#!/usr/bin/env python3
"""
Sistema de BÃºsqueda SemÃ¡ntica para Masa Madre Monterrey
- IntegraciÃ³n con Claude para generaciÃ³n de respuestas
- Historial de conversaciÃ³n para contexto continuo
- Sistema de retroalimentaciÃ³n para mejora continua
"""

import os
import json
import logging
from datetime import datetime
from dotenv import load_dotenv
from pinecone import Pinecone
from anthropic import Anthropic
from langchain.prompts import PromptTemplate
from conversation_history import ConversationHistory
from feedback_system import record_feedback
from mistralai import Mistral

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("semantic_search.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# Cargar variables de entorno
load_dotenv()

def get_pinecone_index():
    """Obtiene el Ã­ndice de Pinecone para bÃºsqueda semÃ¡ntica"""
    pc = Pinecone(api_key=os.getenv('PINECONE_API_KEY'))
    index_name = os.getenv('PINECONE_INDEX_NAME', 'masa-madre-products')
    
    # Usar Mistral para embeddings
    client = Mistral(api_key=os.getenv('MISTRAL_API_KEY'))
    
    class MistralEmbeddings:
        def embed_documents(self, texts):
            response = client.embeddings.create(
                model="mistral-embed",
                inputs=texts
            )
            return [data.embedding for data in response.data]
        
        def embed_query(self, text):
            response = client.embeddings.create(
                model="mistral-embed",
                inputs=[text]
            )
            return response.data[0].embedding
    
    # Crear Ã­ndice de Pinecone
    index = pc.Index(index_name)
    
    return index, MistralEmbeddings()

def create_claude_qa_chain(conversation_history=None):
    """Crea una cadena de preguntas y respuestas usando Claude"""
    # Configurar template de prompt
    template = """Eres un asistente de panaderÃ­a especializado en masa madre para Masa Madre Monterrey.
BasÃ¡ndote en la siguiente informaciÃ³n, responde a la consulta del cliente de manera Ãºtil, amable y profesional.
Si no estÃ¡s seguro de algo, indica que verificarÃ¡s la informaciÃ³n.

{context}

{conversation_context}

Consulta del cliente: {question}

Respuesta:"""
    
    QA_CHAIN_PROMPT = PromptTemplate.from_template(template)
    
    # Configurar cliente Claude
    client = Anthropic(api_key=os.getenv('ANTHROPIC_API_KEY'))
    
    def generate_response(prompt):
        try:
            response = client.messages.create(
                model="claude-sonnet-4-20250514",
                max_tokens=512,
                temperature=0.3,
                messages=[
                    {"role": "user", "content": prompt}
                ]
            )
            return response.content[0].text
        except Exception as e:
            logger.error(f"Error al generar respuesta con Claude: {str(e)}")
            return "Lo siento, estoy teniendo problemas para procesar tu consulta. Por favor, intÃ©ntalo de nuevo mÃ¡s tarde."
    
    # Obtener vector store
    index, embeddings = get_pinecone_index()
    
    def similarity_search(query, k=3):
        """Realiza bÃºsqueda semÃ¡ntica y formatea los resultados"""
        # Generar embedding de la consulta
        query_embedding = embeddings.embed_query(query)
        
        # Buscar en Pinecone
        results = index.query(
            vector=query_embedding,
            top_k=k,
            include_metadata=True
        )
        
        # Formatear resultados
        documents = []
        for match in results['matches']:
            # Decodificar sale_info si existe
            sale_info = []
            if match['metadata'].get('sale_info'):
                try:
                    sale_info = json.loads(match['metadata']['sale_info'])
                except:
                    pass
            
            # Construir contenido alternativo
            content = f"TÃ­tulo: {match['metadata']['title']}\n"
            content += f"CategorÃ­a: {match['metadata']['category']}\n"
            content += f"Precio: {match['metadata']['price_range']}\n"
            content += f"Disponibilidad: {match['metadata']['availability']}\n"
            content += f"URL: {match['metadata']['source_url']}\n"
            
            # Formatear informaciÃ³n de oferta
            sale_text = ""
            if match['metadata'].get('has_active_sale') == 'True' and sale_info:
                sale_text = "\n\nğŸ”” OFERTA VIGENTE: "
                for i, sale in enumerate(sale_info[:2], 1):
                    sale_text += f"\n{i}. {sale['variant_title']}: De ${sale['original_price']:.2f} a ${sale['current_price']:.2f} MXN ({sale['discount_percent']}% OFF)"
            
            # Crear documento con el contenido alternativo
            doc = {
                'page_content': content + sale_text,
                'metadata': {
                    'title': match['metadata']['title'],
                    'url': match['metadata']['source_url'],
                    'price_range': match['metadata']['price_range'],
                    'availability': match['metadata']['availability'],
                    'category': match['metadata']['category']
                }
            }
            documents.append(doc)
        
        return documents
    
    # Crear cadena de QA personalizada
    def qa_chain(query):
        # Recuperar documentos relevantes
        docs = similarity_search(query, k=3)
        
        # Formatear contexto
        context = "\n\n".join([doc['page_content'] for doc in docs])
        
        # AÃ±adir historial de conversaciÃ³n si existe
        conversation_context = ""
        if conversation_history:
            conversation_context = conversation_history.get_context()
        
        # Crear prompt completo
        prompt = QA_CHAIN_PROMPT.format(
            context=context,
            conversation_context=conversation_context,
            question=query
        )
        
        # Obtener respuesta de Claude
        response = generate_response(prompt)
        
        # AÃ±adir el intercambio al historial (CORRECCIÃ“N CLAVE)
        if conversation_history:
            conversation_history.add_exchange(query, response, docs)
        
        return {
            "result": response,
            "source_documents": docs
        }
    
    return qa_chain

def generate_chatbot_response(query, user_id=None, conversation_history=None):
    """
    Genera una respuesta para el chatbot usando bÃºsqueda semÃ¡ntica con Claude
    
    Args:
        query (str): Consulta del usuario
        user_id (str): ID Ãºnico del usuario (opcional)
        conversation_history (ConversationHistory): Historial existente (opcional)
    
    Returns:
        dict: Diccionario con la respuesta, fuentes y proveedor utilizado
    """
    try:
        # Usar el historial proporcionado o crear uno nuevo
        if conversation_history is None:
            conversation_history = ConversationHistory(user_id=user_id)
        
        # Usar siempre Claude
        logger.info("âœ… Usando Claude para generar respuesta")
        print("âœ… Usando Claude para generar respuesta")
        qa_chain = create_claude_qa_chain(conversation_history=conversation_history)
        
        # Generar respuesta
        result = qa_chain(query)
        
        # Extraer informaciÃ³n relevante
        response = result['result']
        sources = []
        
        for doc in result['source_documents']:
            metadata = doc['metadata']
            sources.append({
                'title': metadata.get('title', 'Producto sin tÃ­tulo'),
                'url': metadata.get('url', ''),
                'price': metadata.get('price_range', 'Consultar'),
                'availability': metadata.get('availability', 'No disponible'),
                'category': metadata.get('category', 'otro')
            })
        
        # Mostrar la respuesta al usuario
        print("\n" + "="*50)
        print(f"ğŸ¤– Respuesta del chatbot:")
        print(f"\n{response}\n")
        
        # Mostrar fuentes utilizadas
        print("Fuentes utilizadas:")
        for i, source in enumerate(sources, 1):
            print(f"\n{i}. {source['title']}")
            print(f"   CategorÃ­a: {source['category']}")
            print(f"   Precio: {source['price']}")
            print(f"   Disponibilidad: {source['availability']}")
            print(f"   URL: {source['url']}")
        
        # RetroalimentaciÃ³n discreta - MUY IMPORTANTE: No interrumpe el flujo
        print("\nÂ¿Esta respuesta fue Ãºtil? ğŸ‘ ğŸ‘  (responde con estos emojis)")
        
        # Verificar si el usuario respondiÃ³ con emojis de retroalimentaciÃ³n
        if query.strip() in ["ğŸ‘", "ğŸ‘"]:
            rating = 5 if query.strip() == "ğŸ‘" else 1
            record_feedback(
                query=conversation_history.get_full_history()[-2]['query'],
                response=conversation_history.get_full_history()[-2]['response'],
                provider="claude",
                rating=rating,
                user_comment="",
                session_id=user_id
            )
            print(f"âœ… Â¡Gracias por tu retroalimentaciÃ³n! ({'5 estrellas' if rating == 5 else '1 estrella'})")
        
        # Verificar si el usuario solicita soporte humano
        elif "agente" in query.lower() or "humano" in query.lower() or "representante" in query.lower():
            print("\n" + "="*50)
            print("ğŸ”„ Conectando con un agente humano...")
            print("Un representante se pondrÃ¡ en contacto contigo en breve.")
            print("Mientras tanto, Â¿podrÃ­as compartir tu correo electrÃ³nico o nÃºmero de telÃ©fono?")
            contact_info = input("Tu informaciÃ³n de contacto: ")
            
            # Determinar prioridad
            priority = "alta" if "urgente" in query.lower() or "rapido" in query.lower() else "media"
            
            # Registrar en un sistema de tickets
            try:
                from support_system import create_support_ticket
                create_support_ticket(
                    query=query,
                    response=response,
                    conversation_history=conversation_history.get_full_history(),
                    contact_info=contact_info,
                    priority=priority,
                    reason="Solicitud de soporte humano por el usuario"
                )
                print("âœ… Ticket de soporte creado. Un representante se contactarÃ¡ contigo pronto.")
            except Exception as e:
                logger.error(f"âŒ Error al crear ticket de soporte: {str(e)}")
                print("âš ï¸ Hubo un problema al crear tu ticket. Por favor, contacta directamente a soporte@masamadremonterrey.com")
        
        # Verificar si debe mostrarse el widget detallado (solo en casos especÃ­ficos)
        else:
            # Palabras clave que indican frustraciÃ³n
            frustration_keywords = [
                'no entiendo', 'repetir', 'no funciona', 'error', 'mal', 
                'incorrecto', 'frustrado', 'confundido', 'ayuda', 'soporte',
                'agente', 'humano', 'representante', 'no sirve'
            ]
            
            # Verificar si hay seÃ±ales de frustraciÃ³n
            should_show = False
            if any(keyword in query.lower() for keyword in frustration_keywords):
                should_show = True
            
            # Si el usuario ha hecho mÃ¡s de 3 preguntas sin resolver su problema
            elif len(conversation_history.get_full_history()) > 3:
                should_show = True
            
            # Si la Ãºltima respuesta fue muy corta (posible error)
            elif len(response) < 50:
                should_show = True
            
            # Si el usuario calificÃ³ negativamente antes
            elif any(ex.get('feedback_rating', 5) < 3 for ex in conversation_history.get_full_history()):
                should_show = True
            
            # Mostrar widget detallado si se cumplen las condiciones
            if should_show:
                print("\n" + "="*50)
                print("ğŸ™ Notamos que estÃ¡s teniendo dificultades. Â¿Te gustarÃ­a calificar esta conversaciÃ³n para ayudarnos a mejorar?")
                print("1. Muy Ãºtil (5 estrellas)")
                print("2. Ãštil (4 estrellas)")
                print("3. Neutral (3 estrellas)")
                print("4. Poco Ãºtil (2 estrellas)")
                print("5. No Ãºtil (1 estrella)")
                
                try:
                    rating_input = input("Califica (1-5, Enter para omitir): ")
                    if rating_input.strip():
                        rating = int(rating_input)
                        if 1 <= rating <= 5:
                            comment = input("Comentarios adicionales: ")
                            # Registrar retroalimentaciÃ³n
                            record_feedback(
                                query=query,
                                response=response,
                                provider="claude",
                                rating=rating,
                                user_comment=comment,
                                session_id=user_id
                            )
                            print("âœ… Â¡Gracias por tu retroalimentaciÃ³n!")
                        else:
                            print("âš ï¸  CalificaciÃ³n invÃ¡lida. Debe ser un nÃºmero entre 1 y 5.")
                except ValueError:
                    print("âš ï¸  Entrada invÃ¡lida. Se requiere un nÃºmero entre 1 y 5.")
        
        # Devolver los datos
        return {
            'response': response,
            'sources': sources,
            'provider': "claude",
            'conversation_history': conversation_history
        }
    
    except Exception as e:
        error_msg = f"âŒ Error al generar respuesta: {str(e)}"
        logger.error(error_msg)
        print(error_msg)
        
        # Mostrar mensaje de error al usuario
        error_response = (
            "Lo siento, estoy teniendo problemas para procesar tu consulta. "
            "Por favor, intÃ©ntalo de nuevo mÃ¡s tarde."
        )
        print("\n" + "="*50)
        print(f"ğŸ¤– Respuesta del chatbot (error):")
        print(f"\n{error_response}\n")
        
        # Registrar el error en el sistema de retroalimentaciÃ³n
        try:
            record_feedback(
                query=query,
                response=error_response,
                provider="claude",
                rating=1,
                user_comment=f"Error tÃ©cnico: {str(e)}",
                session_id=user_id
            )
        except Exception as fb_error:
            logger.error(f"âŒ Error al registrar retroalimentaciÃ³n de error: {str(fb_error)}")
        
        return {
            'response': error_response,
            'sources': [],
            'provider': "claude"
        }


def search_products(query, top_k=3):
    """Busca productos relevantes usando Mistral y Pinecone"""
    # Inicializar Pinecone
    pc = Pinecone(api_key=os.getenv('PINECONE_API_KEY'))
    index = pc.Index(os.getenv('PINECONE_INDEX_NAME', 'masa-madre-products'))
    
    # Generar embedding con Mistral
    client = Mistral(api_key=os.getenv('MISTRAL_API_KEY'))
    response = client.embeddings.create(
        model="mistral-embed",
        inputs=[query]
    )
    query_embedding = response.data[0].embedding
    
    # Buscar en Pinecone
    results = index.query(
        vector=query_embedding,
        top_k=top_k,
        include_metadata=True
    )
    
    # Formatear resultados
    formatted_results = []
    for match in results['matches']:
        # Decodificar sale_info si existe
        sale_info = []
        if match['metadata'].get('sale_info'):
            try:
                sale_info = json.loads(match['metadata']['sale_info'])
            except:
                pass
        
        formatted_results.append({
            'id': match['id'],
            'score': match['score'],
            'metadata': {
                'title': match['metadata']['title'],
                'url': match['metadata']['source_url'],
                'price': match['metadata']['price_range'],
                'availability': match['metadata']['availability'],
                'sale_info': sale_info,
                'has_active_sale': match['metadata'].get('has_active_sale', 'False')
            }
        })
    
    return formatted_results

def handle_feedback(query, chatbot_response, user_id):
    """Maneja la retroalimentaciÃ³n del usuario de manera separada"""
    print("\n" + "="*50)
    print("ğŸ” Â¿Te fue Ãºtil esta respuesta?")
    print("1. ğŸ‘ Muy Ãºtil (5 estrellas)")
    print("2. ğŸ‘ Ãštil (4 estrellas)")
    print("3. ğŸ‘ Neutral (3 estrellas)")
    print("4. ğŸ‘ Poco Ãºtil (2 estrellas)")
    print("5. ğŸ‘ No Ãºtil (1 estrella)")
    
    try:
        rating_input = input("Selecciona una opciÃ³n (1-5, o presiona Enter para omitir): ")
        if rating_input.strip():
            rating = int(rating_input)
            if 1 <= rating <= 5:
                comment = input("Comentario adicional (opcional): ")
                # Registrar retroalimentaciÃ³n
                record_feedback(
                    query=query,
                    response=chatbot_response['response'],
                    provider="claude",
                    rating=rating,
                    user_comment=comment,
                    session_id=user_id
                )
                print("âœ… Â¡Gracias por tu retroalimentaciÃ³n!")
            else:
                print("âš ï¸  CalificaciÃ³n invÃ¡lida. Debe ser un nÃºmero entre 1 y 5.")
    except ValueError:
        print("âš ï¸  Entrada invÃ¡lida. Se requiere un nÃºmero entre 1 y 5.")

def verify_pinecone_connection():
    """Verifica la conexiÃ³n con Pinecone para monitoreo en producciÃ³n"""
    try:
        from conversation_history import ConversationHistory
        test_history = ConversationHistory(user_id="test_connection")
        
        # Intentar subir un vector de prueba
        test_history.add_exchange(
            "Consulta de prueba",
            "Respuesta de prueba para verificar conexiÃ³n con Pinecone",
            []
        )
        
        # Verificar estadÃ­sticas
        if test_history.pinecone_index:
            stats = test_history.pinecone_index.describe_index_stats()
            logger.info(f"ğŸ“Š VerificaciÃ³n de Pinecone exitosa. Total de vectores: {stats.total_vector_count}")
            return True
        
        logger.warning("âš ï¸ No hay conexiÃ³n con Pinecone (funcionalidad de historial deshabilitada)")
        return False
        
    except Exception as e:
        logger.error(f"âŒ Error al verificar conexiÃ³n con Pinecone: {str(e)}")
        return False

def should_show_feedback_widget(query, response, conversation_history):
    """Determina si debe mostrarse el widget de retroalimentaciÃ³n detallada"""
    # Palabras clave que indican frustraciÃ³n
    frustration_keywords = [
        'no entiendo', 'repetir', 'no funciona', 'error', 'mal', 
        'incorrecto', 'frustrado', 'confundido', 'ayuda', 'soporte',
        'agente', 'humano', 'representante', 'no sirve'
    ]
    
    # Verificar si hay seÃ±ales de frustraciÃ³n en la consulta actual
    if any(keyword in query.lower() for keyword in frustration_keywords):
        return True
    
    # Si el usuario ha hecho mÃ¡s de 3 preguntas sin resolver su problema
    if len(conversation_history.get_full_history()) > 3:
        return True
    
    # Si la Ãºltima respuesta fue muy corta (posible error)
    if len(response) < 50:
        return True
    
    # Si el usuario calificÃ³ negativamente antes
    recent_feedback = [ex for ex in conversation_history.get_full_history() 
                      if 'feedback_rating' in ex]
    if recent_feedback and min(r['feedback_rating'] for r in recent_feedback) < 3:
        return True
    
    return False


def handle_feedback_at_end(user_id, conversation_history):
    """Muestra un widget de retroalimentaciÃ³n simple al final de la conversaciÃ³n"""
    if not conversation_history or not conversation_history.get_full_history():
        return
    
    # Detectar si el usuario estÃ¡ terminando la conversaciÃ³n
    last_query = conversation_history.get_full_history()[-1]['query'].lower()
    if any(phrase in last_query for phrase in ["gracias", "adiÃ³s", "adios", "hasta luego", "chao", "salir", "exit", "quit"]):
        print("\n" + "="*50)
        print("ğŸ™ Â¡Gracias por usar nuestro asistente de panaderÃ­a!")
        print("Â¿Fue Ãºtil esta conversaciÃ³n? Responde con 1-5 estrellas")
        
        try:
            rating_input = input("CalificaciÃ³n (1-5): ")
            if rating_input.strip():
                rating = int(rating_input)
                if 1 <= rating <= 5:
                    # Registrar retroalimentaciÃ³n para toda la conversaciÃ³n
                    from feedback_system import record_conversation_feedback
                    record_conversation_feedback(
                        conversation=conversation_history.get_full_history(),
                        rating=rating,
                        user_comment="",
                        session_id=user_id
                    )
                    print("âœ… Â¡Gracias por tu retroalimentaciÃ³n!")
                else:
                    print("âš ï¸  CalificaciÃ³n invÃ¡lida. Debe ser un nÃºmero entre 1 y 5.")
        except ValueError:
            print("âš ï¸  Entrada invÃ¡lida. Se requiere un nÃºmero entre 1 y 5.")

def handle_human_support_request(query, response, conversation_history, user_id):
    """Gestiona la solicitud de soporte humano"""
    print("\n" + "="*50)
    print("ğŸ”„ Conectando con un agente humano...")
    print("Un representante se pondrÃ¡ en contacto contigo en breve.")
    print("Mientras tanto, Â¿podrÃ­as compartir tu correo electrÃ³nico o nÃºmero de telÃ©fono?")
    contact_info = input("Tu informaciÃ³n de contacto: ")
    
    # Determinar prioridad
    priority = "alta" if "urgente" in query.lower() or "rapido" in query.lower() else "media"
    
    # Registrar en un sistema de tickets
    try:
        from support_system import create_support_ticket
        create_support_ticket(
            query=query,
            response=response,
            conversation_history=conversation_history.get_full_history(),
            contact_info=contact_info,
            priority=priority,
            reason="Solicitud de soporte humano por el usuario"
        )
        print("âœ… Ticket de soporte creado. Un representante se contactarÃ¡ contigo pronto.")
    except Exception as e:
        logger.error(f"âŒ Error al crear ticket de soporte: {str(e)}")
        print("âš ï¸ Hubo un problema al crear tu ticket. Por favor, contacta directamente a soporte@masamadremonterrey.com")

if __name__ == "__main__":
    # ConfiguraciÃ³n inicial
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler("semantic_search.log"),
            logging.StreamHandler()
        ]
    )
    logger = logging.getLogger(__name__)
    
    # Cargar variables de entorno
    load_dotenv()
    
    # Obtener ID del usuario (en producciÃ³n vendrÃ­a de la sesiÃ³n web)
    user_id = input("Ingresa tu ID de usuario (o presiona Enter para uno temporal): ").strip()
    if not user_id:
        user_id = f"user_{int(datetime.now().timestamp())}"
    
    print(f"\nğŸ‘‹ Â¡Hola! Soy tu asistente de panaderÃ­a especializado en masa madre.")
    print(f"Tu ID de sesiÃ³n: {user_id}")
    print("Escribe 'salir' para terminar la conversaciÃ³n.\n")
    
    # Inicializar historial de conversaciÃ³n
    conversation_history = ConversationHistory(user_id=user_id)
    
    # Bucle de conversaciÃ³n PRINCIPAL
    while True:
        # Solicitar consulta
        query = input("ğŸ” Tu consulta: ").strip()
        
        if not query:
            continue
            
        # Manejar comandos especiales de salida
        if query.lower() in ['salir', 'exit', 'quit', 'adiÃ³s', 'adios', 'gracias']:
            # Manejar retroalimentaciÃ³n al final
            if len(conversation_history.get_full_history()) > 1:
                print("\n" + "="*50)
                print("ğŸ™ Â¡Gracias por usar nuestro asistente de panaderÃ­a!")
                print("Â¿Fue Ãºtil esta conversaciÃ³n? Responde con 1-5 estrellas")
                
                try:
                    rating_input = input("CalificaciÃ³n (1-5): ")
                    if rating_input.strip():
                        rating = int(rating_input)
                        if 1 <= rating <= 5:
                            from feedback_system import record_conversation_feedback
                            record_conversation_feedback(
                                conversation=conversation_history.get_full_history(),
                                rating=rating,
                                user_comment="",
                                session_id=user_id
                            )
                            print("âœ… Â¡Gracias por tu retroalimentaciÃ³n!")
                        else:
                            print("âš ï¸  CalificaciÃ³n invÃ¡lida. Debe ser un nÃºmero entre 1 y 5.")
                except ValueError:
                    print("âš ï¸  Entrada invÃ¡lida. Se requiere un nÃºmero entre 1 y 5.")
            
            print("\nğŸ‘‹ Â¡Hasta luego! No dudes en volver si tienes mÃ¡s preguntas.")
            break
        
        # Mostrar resultados de bÃºsqueda semÃ¡ntica
        print(f"ğŸ” Consulta: '{query}'\n")
        
        print("ğŸ“ Resultados de bÃºsqueda semÃ¡ntica:")
        try:
            results = search_products(query)
            for i, result in enumerate(results, 1):
                print(f"\n{i}. {result['metadata']['title']}")
                print(f"   Similitud: {result['score']:.4f}")
                print(f"   Precio: {result['metadata']['price']}")
                print(f"   Disponibilidad: {result['metadata']['availability']}")
                
                # Mostrar informaciÃ³n de oferta si existe
                if result['metadata']['has_active_sale'] == 'True' and result['metadata']['sale_info']:
                    print("   ğŸ Oferta:")
                    for sale in result['metadata']['sale_info'][:2]:
                        print(f"      - {sale['variant_title']}: ${sale['original_price']:.2f} â†’ ${sale['current_price']:.2f} ({sale['discount_percent']}% OFF)")
                
                print(f"   URL: {result['metadata']['url']}")
        except Exception as e:
            logger.error(f"âŒ Error al realizar bÃºsqueda semÃ¡ntica: {str(e)}")
            print("âš ï¸  Hubo un problema al buscar productos relacionados. Continuando con la generaciÃ³n de respuesta...")
        
        # Generar respuesta con historial
        try:
            chatbot_response = generate_chatbot_response(
                query, 
                user_id=user_id,
                conversation_history=conversation_history
            )
            
            # Actualizar historial de conversaciÃ³n
            if 'conversation_history' in chatbot_response:
                conversation_history = chatbot_response['conversation_history']
        except Exception as e:
            logger.error(f"âŒ Error al generar respuesta del chatbot: {str(e)}")
            print("\n" + "="*50)
            print("ğŸ¤– Respuesta del chatbot (error):")
            print("\nLo siento, estoy teniendo problemas para procesar tu consulta. Por favor, intÃ©ntalo de nuevo mÃ¡s tarde.")
            
            # Registrar error en el historial
            conversation_history.add_exchange(
                query,
                "Error tÃ©cnico - Consulta no procesada",
                []
            )
