#!/usr/bin/env python3
"""
Sistema de B√∫squeda Sem√°ntica para Masa Madre Monterrey
- Integraci√≥n con Claude para generaci√≥n de respuestas
- Historial de conversaci√≥n para contexto continuo
- Sistema de retroalimentaci√≥n para mejora continua
"""

import os
import json
import logging
from datetime import datetime
from dotenv import load_dotenv
from pinecone import Pinecone
from anthropic import Anthropic
from langchain.prompts import PromptTemplate
from conversation_history import ConversationHistory
from feedback_system import record_feedback
from mistralai import Mistral

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("semantic_search.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# Cargar variables de entorno
load_dotenv()

def get_pinecone_index():
    """Obtiene el √≠ndice de Pinecone para b√∫squeda sem√°ntica"""
    pc = Pinecone(api_key=os.getenv('PINECONE_API_KEY'))
    index_name = os.getenv('PINECONE_INDEX_NAME', 'masa-madre-products')
    
    # Usar Mistral para embeddings
    client = Mistral(api_key=os.getenv('MISTRAL_API_KEY'))
    
    class MistralEmbeddings:
        def embed_documents(self, texts):
            response = client.embeddings.create(
                model="mistral-embed",
                inputs=texts
            )
            return [data.embedding for data in response.data]
        
        def embed_query(self, text):
            response = client.embeddings.create(
                model="mistral-embed",
                inputs=[text]
            )
            return response.data[0].embedding
    
    # Crear √≠ndice de Pinecone
    index = pc.Index(index_name)
    
    return index, MistralEmbeddings()

def create_claude_qa_chain(conversation_history=None):
    """Crea una cadena de preguntas y respuestas usando Claude"""
    # Configurar template de prompt
    template = """Eres un asistente de panader√≠a especializado en masa madre para Masa Madre Monterrey.
Bas√°ndote en la siguiente informaci√≥n, responde a la consulta del cliente de manera √∫til, amable y profesional.
Si no est√°s seguro de algo, indica que verificar√°s la informaci√≥n.

{context}

{conversation_context}

Consulta del cliente: {question}

Respuesta:"""
    
    QA_CHAIN_PROMPT = PromptTemplate.from_template(template)
    
    # Configurar cliente Claude
    client = Anthropic(api_key=os.getenv('ANTHROPIC_API_KEY'))
    
    def generate_response(prompt):
        try:
            response = client.messages.create(
                model="claude-sonnet-4-20250514",
                max_tokens=512,
                temperature=0.3,
                messages=[
                    {"role": "user", "content": prompt}
                ]
            )
            return response.content[0].text
        except Exception as e:
            logger.error(f"Error al generar respuesta con Claude: {str(e)}")
            return "Lo siento, estoy teniendo problemas para procesar tu consulta. Por favor, int√©ntalo de nuevo m√°s tarde."
    
    # Obtener vector store
    index, embeddings = get_pinecone_index()
    
    def similarity_search(query, k=3):
        """Realiza b√∫squeda sem√°ntica y formatea los resultados"""
        # Generar embedding de la consulta
        query_embedding = embeddings.embed_query(query)
        
        # Buscar en Pinecone
        results = index.query(
            vector=query_embedding,
            top_k=k,
            include_metadata=True
        )
        
        # Formatear resultados
        documents = []
        for match in results['matches']:
            # Decodificar sale_info si existe
            sale_info = []
            if match['metadata'].get('sale_info'):
                try:
                    sale_info = json.loads(match['metadata']['sale_info'])
                except:
                    pass
            
            # Construir contenido alternativo
            content = f"T√≠tulo: {match['metadata']['title']}\n"
            content += f"Categor√≠a: {match['metadata']['category']}\n"
            content += f"Precio: {match['metadata']['price_range']}\n"
            content += f"Disponibilidad: {match['metadata']['availability']}\n"
            content += f"URL: {match['metadata']['source_url']}\n"
            
            # Formatear informaci√≥n de oferta
            sale_text = ""
            if match['metadata'].get('has_active_sale') == 'True' and sale_info:
                sale_text = "\n\nüîî OFERTA VIGENTE: "
                for i, sale in enumerate(sale_info[:2], 1):
                    sale_text += f"\n{i}. {sale['variant_title']}: De ${sale['original_price']:.2f} a ${sale['current_price']:.2f} MXN ({sale['discount_percent']}% OFF)"
            
            # Crear documento con el contenido alternativo
            doc = {
                'page_content': content + sale_text,
                'metadata': {
                    'title': match['metadata']['title'],
                    'url': match['metadata']['source_url'],
                    'price_range': match['metadata']['price_range'],
                    'availability': match['metadata']['availability'],
                    'category': match['metadata']['category']
                }
            }
            documents.append(doc)
        
        return documents
    
    # Crear cadena de QA personalizada
    def qa_chain(query):
        # Recuperar documentos relevantes
        docs = similarity_search(query, k=3)
        
        # Formatear contexto
        context = "\n\n".join([doc['page_content'] for doc in docs])
        
        # A√±adir historial de conversaci√≥n si existe
        conversation_context = ""
        if conversation_history:
            conversation_context = conversation_history.get_context()
        
        # Crear prompt completo
        prompt = QA_CHAIN_PROMPT.format(
            context=context,
            conversation_context=conversation_context,
            question=query
        )
        
        # Obtener respuesta de Claude
        response = generate_response(prompt)
        
        # A√±adir el intercambio al historial (CORRECCI√ìN CLAVE)
        if conversation_history:
            conversation_history.add_exchange(query, response, docs)
        
        return {
            "result": response,
            "source_documents": docs
        }
    
    return qa_chain

def generate_chatbot_response(query, user_id=None, conversation_history=None):
    """
    Genera una respuesta para el chatbot usando b√∫squeda sem√°ntica con Claude
    
    Args:
        query (str): Consulta del usuario
        user_id (str): ID √∫nico del usuario (opcional)
        conversation_history (ConversationHistory): Historial existente (opcional)
    
    Returns:
        dict: Diccionario con la respuesta, fuentes y proveedor utilizado
    """
    try:
        # Usar el historial proporcionado o crear uno nuevo
        if conversation_history is None:
            conversation_history = ConversationHistory(user_id=user_id)
        
        # Usar siempre Claude
        logger.info("‚úÖ Usando Claude para generar respuesta")
        print("‚úÖ Usando Claude para generar respuesta")
        qa_chain = create_claude_qa_chain(conversation_history=conversation_history)
        
        # Generar respuesta
        result = qa_chain(query)
        
        # Extraer informaci√≥n relevante
        response = result['result']
        sources = []
        
        for doc in result['source_documents']:
            metadata = doc['metadata']
            sources.append({
                'title': metadata.get('title', 'Producto sin t√≠tulo'),
                'url': metadata.get('url', ''),
                'price': metadata.get('price_range', 'Consultar'),
                'availability': metadata.get('availability', 'No disponible'),
                'category': metadata.get('category', 'otro')
            })
        
        # Mostrar la respuesta al usuario
        print("\n" + "="*50)
        print(f"ü§ñ Respuesta del chatbot:")
        print(f"\n{response}\n")
        
        # Mostrar fuentes utilizadas
        print("Fuentes utilizadas:")
        for i, source in enumerate(sources, 1):
            print(f"\n{i}. {source['title']}")
            print(f"   Categor√≠a: {source['category']}")
            print(f"   Precio: {source['price']}")
            print(f"   Disponibilidad: {source['availability']}")
            print(f"   URL: {source['url']}")
        
        # Retroalimentaci√≥n discreta - MUY IMPORTANTE: No interrumpe el flujo
        print("\n¬øEsta respuesta fue √∫til? üëç üëé  (responde con estos emojis)")
        
        # Verificar si el usuario respondi√≥ con emojis de retroalimentaci√≥n
        if query.strip() in ["üëç", "üëé"]:
            rating = 5 if query.strip() == "üëç" else 1
            record_feedback(
                query=conversation_history.get_full_history()[-2]['query'],
                response=conversation_history.get_full_history()[-2]['response'],
                provider="claude",
                rating=rating,
                user_comment="",
                session_id=user_id
            )
            print(f"‚úÖ ¬°Gracias por tu retroalimentaci√≥n! ({'5 estrellas' if rating == 5 else '1 estrella'})")
        
        # Verificar si el usuario solicita soporte humano
        elif "agente" in query.lower() or "humano" in query.lower() or "representante" in query.lower():
            print("\n" + "="*50)
            print("üîÑ Conectando con un agente humano...")
            print("Un representante se pondr√° en contacto contigo en breve.")
            print("Mientras tanto, ¬øpodr√≠as compartir tu correo electr√≥nico o n√∫mero de tel√©fono?")
            contact_info = input("Tu informaci√≥n de contacto: ")
            
            # Determinar prioridad
            priority = "alta" if "urgente" in query.lower() or "rapido" in query.lower() else "media"
            
            # Registrar en un sistema de tickets
            try:
                from support_system import create_support_ticket
                create_support_ticket(
                    query=query,
                    response=response,
                    conversation_history=conversation_history.get_full_history(),
                    contact_info=contact_info,
                    priority=priority,
                    reason="Solicitud de soporte humano por el usuario"
                )
                print("‚úÖ Ticket de soporte creado. Un representante se contactar√° contigo pronto.")
            except Exception as e:
                logger.error(f"‚ùå Error al crear ticket de soporte: {str(e)}")
                print("‚ö†Ô∏è Hubo un problema al crear tu ticket. Por favor, contacta directamente a soporte@masamadremonterrey.com")
        
        # Verificar si debe mostrarse el widget detallado (solo en casos espec√≠ficos)
        else:
            # Palabras clave que indican frustraci√≥n
            frustration_keywords = [
                'no entiendo', 'repetir', 'no funciona', 'error', 'mal', 
                'incorrecto', 'frustrado', 'confundido', 'ayuda', 'soporte',
                'agente', 'humano', 'representante', 'no sirve'
            ]
            
            # Verificar si hay se√±ales de frustraci√≥n
            should_show = False
            if any(keyword in query.lower() for keyword in frustration_keywords):
                should_show = True
            
            # Si el usuario ha hecho m√°s de 3 preguntas sin resolver su problema
            elif len(conversation_history.get_full_history()) > 3:
                should_show = True
            
            # Si la √∫ltima respuesta fue muy corta (posible error)
            elif len(response) < 50:
                should_show = True
            
            # Si el usuario calific√≥ negativamente antes
            elif any(ex.get('feedback_rating', 5) < 3 for ex in conversation_history.get_full_history()):
                should_show = True
            
            # Mostrar widget detallado si se cumplen las condiciones
            if should_show:
                print("\n" + "="*50)
                print("üôè Notamos que est√°s teniendo dificultades. ¬øTe gustar√≠a calificar esta conversaci√≥n para ayudarnos a mejorar?")
                print("1. Muy √∫til (5 estrellas)")
                print("2. √ötil (4 estrellas)")
                print("3. Neutral (3 estrellas)")
                print("4. Poco √∫til (2 estrellas)")
                print("5. No √∫til (1 estrella)")
                
                try:
                    rating_input = input("Califica (1-5, Enter para omitir): ")
                    if rating_input.strip():
                        rating = int(rating_input)
                        if 1 <= rating <= 5:
                            comment = input("Comentarios adicionales: ")
                            # Registrar retroalimentaci√≥n
                            record_feedback(
                                query=query,
                                response=response,
                                provider="claude",
                                rating=rating,
                                user_comment=comment,
                                session_id=user_id
                            )
                            print("‚úÖ ¬°Gracias por tu retroalimentaci√≥n!")
                        else:
                            print("‚ö†Ô∏è  Calificaci√≥n inv√°lida. Debe ser un n√∫mero entre 1 y 5.")
                except ValueError:
                    print("‚ö†Ô∏è  Entrada inv√°lida. Se requiere un n√∫mero entre 1 y 5.")
        
        # Devolver los datos
        return {
            'response': response,
            'sources': sources,
            'provider': "claude",
            'conversation_history': conversation_history
        }
    
    except Exception as e:
        error_msg = f"‚ùå Error al generar respuesta: {str(e)}"
        logger.error(error_msg)
        print(error_msg)
        
        # Mostrar mensaje de error al usuario
        error_response = (
            "Lo siento, estoy teniendo problemas para procesar tu consulta. "
            "Por favor, int√©ntalo de nuevo m√°s tarde."
        )
        print("\n" + "="*50)
        print(f"ü§ñ Respuesta del chatbot (error):")
        print(f"\n{error_response}\n")
        
        # Registrar el error en el sistema de retroalimentaci√≥n
        try:
            record_feedback(
                query=query,
                response=error_response,
                provider="claude",
                rating=1,
                user_comment=f"Error t√©cnico: {str(e)}",
                session_id=user_id
            )
        except Exception as fb_error:
            logger.error(f"‚ùå Error al registrar retroalimentaci√≥n de error: {str(fb_error)}")
        
        return {
            'response': error_response,
            'sources': [],
            'provider': "claude"
        }


def search_products(query, top_k=3):
    """Busca productos relevantes usando Mistral y Pinecone"""
    # Inicializar Pinecone
    pc = Pinecone(api_key=os.getenv('PINECONE_API_KEY'))
    index = pc.Index(os.getenv('PINECONE_INDEX_NAME', 'masa-madre-products'))
    
    # Generar embedding con Mistral
    client = Mistral(api_key=os.getenv('MISTRAL_API_KEY'))
    response = client.embeddings.create(
        model="mistral-embed",
        inputs=[query]
    )
    query_embedding = response.data[0].embedding
    
    # Buscar en Pinecone
    results = index.query(
        vector=query_embedding,
        top_k=top_k,
        include_metadata=True
    )
    
    # Formatear resultados
    formatted_results = []
    for match in results['matches']:
        # Decodificar sale_info si existe
        sale_info = []
        if match['metadata'].get('sale_info'):
            try:
                sale_info = json.loads(match['metadata']['sale_info'])
            except:
                pass
        
        formatted_results.append({
            'id': match['id'],
            'score': match['score'],
            'metadata': {
                'title': match['metadata']['title'],
                'url': match['metadata']['source_url'],
                'price': match['metadata']['price_range'],
                'availability': match['metadata']['availability'],
                'sale_info': sale_info,
                'has_active_sale': match['metadata'].get('has_active_sale', 'False')
            }
        })
    
    return formatted_results

def handle_feedback(query, chatbot_response, user_id):
    """Maneja la retroalimentaci√≥n del usuario de manera separada"""
    print("\n" + "="*50)
    print("üîç ¬øTe fue √∫til esta respuesta?")
    print("1. üëç Muy √∫til (5 estrellas)")
    print("2. üëç √ötil (4 estrellas)")
    print("3. üëç Neutral (3 estrellas)")
    print("4. üëé Poco √∫til (2 estrellas)")
    print("5. üëé No √∫til (1 estrella)")
    
    try:
        rating_input = input("Selecciona una opci√≥n (1-5, o presiona Enter para omitir): ")
        if rating_input.strip():
            rating = int(rating_input)
            if 1 <= rating <= 5:
                comment = input("Comentario adicional (opcional): ")
                # Registrar retroalimentaci√≥n
                record_feedback(
                    query=query,
                    response=chatbot_response['response'],
                    provider="claude",
                    rating=rating,
                    user_comment=comment,
                    session_id=user_id
                )
                print("‚úÖ ¬°Gracias por tu retroalimentaci√≥n!")
            else:
                print("‚ö†Ô∏è  Calificaci√≥n inv√°lida. Debe ser un n√∫mero entre 1 y 5.")
    except ValueError:
        print("‚ö†Ô∏è  Entrada inv√°lida. Se requiere un n√∫mero entre 1 y 5.")

def verify_pinecone_connection():
    """Verifica la conexi√≥n con Pinecone para monitoreo en producci√≥n"""
    try:
        from conversation_history import ConversationHistory
        test_history = ConversationHistory(user_id="test_connection")
        
        # Intentar subir un vector de prueba
        test_history.add_exchange(
            "Consulta de prueba",
            "Respuesta de prueba para verificar conexi√≥n con Pinecone",
            []
        )
        
        # Verificar estad√≠sticas
        if test_history.pinecone_index:
            stats = test_history.pinecone_index.describe_index_stats()
            logger.info(f"üìä Verificaci√≥n de Pinecone exitosa. Total de vectores: {stats.total_vector_count}")
            return True
        
        logger.warning("‚ö†Ô∏è No hay conexi√≥n con Pinecone (funcionalidad de historial deshabilitada)")
        return False
        
    except Exception as e:
        logger.error(f"‚ùå Error al verificar conexi√≥n con Pinecone: {str(e)}")
        return False

def should_show_feedback_widget(query, response, conversation_history):
    """Determina si debe mostrarse el widget de retroalimentaci√≥n detallada"""
    # Palabras clave que indican frustraci√≥n
    frustration_keywords = [
        'no entiendo', 'repetir', 'no funciona', 'error', 'mal', 
        'incorrecto', 'frustrado', 'confundido', 'ayuda', 'soporte',
        'agente', 'humano', 'representante', 'no sirve'
    ]
    
    # Verificar si hay se√±ales de frustraci√≥n en la consulta actual
    if any(keyword in query.lower() for keyword in frustration_keywords):
        return True
    
    # Si el usuario ha hecho m√°s de 3 preguntas sin resolver su problema
    if len(conversation_history.get_full_history()) > 3:
        return True
    
    # Si la √∫ltima respuesta fue muy corta (posible error)
    if len(response) < 50:
        return True
    
    # Si el usuario calific√≥ negativamente antes
    recent_feedback = [ex for ex in conversation_history.get_full_history() 
                      if 'feedback_rating' in ex]
    if recent_feedback and min(r['feedback_rating'] for r in recent_feedback) < 3:
        return True
    
    return False


def handle_feedback_at_end(user_id, conversation_history):
    """Muestra un widget de retroalimentaci√≥n simple al final de la conversaci√≥n"""
    if not conversation_history or not conversation_history.get_full_history():
        return
    
    # Detectar si el usuario est√° terminando la conversaci√≥n
    last_query = conversation_history.get_full_history()[-1]['query'].lower()
    if any(phrase in last_query for phrase in ["gracias", "adi√≥s", "adios", "hasta luego", "chao", "salir", "exit", "quit"]):
        print("\n" + "="*50)
        print("üôè ¬°Gracias por usar nuestro asistente de panader√≠a!")
        print("¬øFue √∫til esta conversaci√≥n? Responde con 1-5 estrellas")
        
        try:
            rating_input = input("Calificaci√≥n (1-5): ")
            if rating_input.strip():
                rating = int(rating_input)
                if 1 <= rating <= 5:
                    # Registrar retroalimentaci√≥n para toda la conversaci√≥n
                    from feedback_system import record_conversation_feedback
                    record_conversation_feedback(
                        conversation=conversation_history.get_full_history(),
                        rating=rating,
                        user_comment="",
                        session_id=user_id
                    )
                    print("‚úÖ ¬°Gracias por tu retroalimentaci√≥n!")
                else:
                    print("‚ö†Ô∏è  Calificaci√≥n inv√°lida. Debe ser un n√∫mero entre 1 y 5.")
        except ValueError:
            print("‚ö†Ô∏è  Entrada inv√°lida. Se requiere un n√∫mero entre 1 y 5.")

def handle_human_support_request(query, response, conversation_history, user_id):
    """Gestiona la solicitud de soporte humano"""
    print("\n" + "="*50)
    print("üîÑ Conectando con un agente humano...")
    print("Un representante se pondr√° en contacto contigo en breve.")
    print("Mientras tanto, ¬øpodr√≠as compartir tu correo electr√≥nico o n√∫mero de tel√©fono?")
    contact_info = input("Tu informaci√≥n de contacto: ")
    
    # Determinar prioridad
    priority = "alta" if "urgente" in query.lower() or "rapido" in query.lower() else "media"
    
    # Registrar en un sistema de tickets
    try:
        from support_system import create_support_ticket
        create_support_ticket(
            query=query,
            response=response,
            conversation_history=conversation_history.get_full_history(),
            contact_info=contact_info,
            priority=priority,
            reason="Solicitud de soporte humano por el usuario"
        )
        print("‚úÖ Ticket de soporte creado. Un representante se contactar√° contigo pronto.")
    except Exception as e:
        logger.error(f"‚ùå Error al crear ticket de soporte: {str(e)}")
        print("‚ö†Ô∏è Hubo un problema al crear tu ticket. Por favor, contacta directamente a soporte@masamadremonterrey.com")

if __name__ == "__main__":
    # Configuraci√≥n inicial
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler("semantic_search.log"),
            logging.StreamHandler()
        ]
    )
    logger = logging.getLogger(__name__)
    
    # Cargar variables de entorno
    load_dotenv()
    
    # Obtener ID del usuario (en producci√≥n vendr√≠a de la sesi√≥n web)
    user_id = input("Ingresa tu ID de usuario (o presiona Enter para uno temporal): ").strip()
    if not user_id:
        user_id = f"user_{int(datetime.now().timestamp())}"
    
    print(f"\nüëã ¬°Hola! Soy tu asistente de panader√≠a especializado en masa madre.")
    print(f"Tu ID de sesi√≥n: {user_id}")
    print("Escribe 'salir' para terminar la conversaci√≥n.\n")
    
    # Inicializar historial de conversaci√≥n
    conversation_history = ConversationHistory(user_id=user_id)
    
    # Bucle de conversaci√≥n PRINCIPAL
    while True:
        # Solicitar consulta
        query = input("üîç Tu consulta: ").strip()
        
        if not query:
            continue
            
        # Manejar comandos especiales de salida
        if query.lower() in ['salir', 'exit', 'quit', 'adi√≥s', 'adios', 'gracias']:
            # Manejar retroalimentaci√≥n al final
            if len(conversation_history.get_full_history()) > 1:
                print("\n" + "="*50)
                print("üôè ¬°Gracias por usar nuestro asistente de panader√≠a!")
                print("¬øFue √∫til esta conversaci√≥n? Responde con 1-5 estrellas")
                
                try:
                    rating_input = input("Calificaci√≥n (1-5): ")
                    if rating_input.strip():
                        rating = int(rating_input)
                        if 1 <= rating <= 5:
                            from feedback_system import record_conversation_feedback
                            record_conversation_feedback(
                                conversation=conversation_history.get_full_history(),
                                rating=rating,
                                user_comment="",
                                session_id=user_id
                            )
                            print("‚úÖ ¬°Gracias por tu retroalimentaci√≥n!")
                        else:
                            print("‚ö†Ô∏è  Calificaci√≥n inv√°lida. Debe ser un n√∫mero entre 1 y 5.")
                except ValueError:
                    print("‚ö†Ô∏è  Entrada inv√°lida. Se requiere un n√∫mero entre 1 y 5.")
            
            print("\nüëã ¬°Hasta luego! No dudes en volver si tienes m√°s preguntas.")
            break
        
        # Mostrar resultados de b√∫squeda sem√°ntica
        print(f"üîç Consulta: '{query}'\n")
        
        print("üìù Resultados de b√∫squeda sem√°ntica:")
        try:
            results = search_products(query)
            for i, result in enumerate(results, 1):
                print(f"\n{i}. {result['metadata']['title']}")
                print(f"   Similitud: {result['score']:.4f}")
                print(f"   Precio: {result['metadata']['price']}")
                print(f"   Disponibilidad: {result['metadata']['availability']}")
                
                # Mostrar informaci√≥n de oferta si existe
                if result['metadata']['has_active_sale'] == 'True' and result['metadata']['sale_info']:
                    print("   üéÅ Oferta:")
                    for sale in result['metadata']['sale_info'][:2]:
                        print(f"      - {sale['variant_title']}: ${sale['original_price']:.2f} ‚Üí ${sale['current_price']:.2f} ({sale['discount_percent']}% OFF)")
                
                print(f"   URL: {result['metadata']['url']}")
        except Exception as e:
            logger.error(f"‚ùå Error al realizar b√∫squeda sem√°ntica: {str(e)}")
            print("‚ö†Ô∏è  Hubo un problema al buscar productos relacionados. Continuando con la generaci√≥n de respuesta...")
        
        # Generar respuesta con historial
        try:
            chatbot_response = generate_chatbot_response(
                query, 
                user_id=user_id,
                conversation_history=conversation_history
            )
            
            # Actualizar historial de conversaci√≥n
            if 'conversation_history' in chatbot_response:
                conversation_history = chatbot_response['conversation_history']
        except Exception as e:
            logger.error(f"‚ùå Error al generar respuesta del chatbot: {str(e)}")
            print("\n" + "="*50)
            print("ü§ñ Respuesta del chatbot (error):")
            print("\nLo siento, estoy teniendo problemas para procesar tu consulta. Por favor, int√©ntalo de nuevo m√°s tarde.")
            
            # Registrar error en el historial
            conversation_history.add_exchange(
                query,
                "Error t√©cnico - Consulta no procesada",
                []
            )
